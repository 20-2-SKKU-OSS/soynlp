{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.46\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import soynlp\n",
    "print(soynlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie comment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentences = 294493\n"
     ]
    }
   ],
   "source": [
    "# movie comments\n",
    "corpus_path = 'merged_comments.txt' # set your data path\n",
    "corpus_path = '/mnt/lovit/works/fastcampus_text_ml/2nd/data/comments_10movies/merged_comments.txt'\n",
    "\n",
    "# <idx, comment, rate>\n",
    "with open(corpus_path, encoding='utf-8') as f:\n",
    "    sentences = [doc.split('\\t')[1] for doc in f]\n",
    "    sentences = [sent for sent in sentences if sent]\n",
    "print('num sentences = %d' % len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=1260, neg=1173, common=12\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 89170 from 294493 sents. mem=0.166 Gb                     \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. mem=0.297 Gb\n",
      "[Noun Extractor] batch prediction was completed for 28290 words\n",
      "[Noun Extractor] checked compounds. discovered 15 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 9458 -> 9335\n",
      "[Noun Extractor] postprocessing ignore_features : 9335 -> 9257\n",
      "[Noun Extractor] postprocessing ignore_NJ : 9257 -> 9131\n",
      "[Noun Extractor] 9131 nouns (15 compounds) with min frequency=2\n",
      "[Noun Extractor] flushing was done. mem=0.333 Gb                    \n",
      "[Noun Extractor] 68.04 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "noun_extractor = LRNounExtractor_v2(\n",
    "    max_left_length=10, max_right_length=9,\n",
    "    verbose=True, min_num_of_features=2,\n",
    "    max_frequency_when_noun_is_eojeol=10,\n",
    "    min_eojeol_frequency=2,\n",
    "    extract_compound=True, extract_pos_feature=False\n",
    ")\n",
    "\n",
    "noun_scores = noun_extractor.train_extract(\n",
    "    sentences,\n",
    "    min_noun_score=0.3,\n",
    "    min_noun_frequency=2,  # 추출되는 명사의 최소 빈도수\n",
    "    min_eojeol_frequency=1,\n",
    "    reset_lrgraph=False    # predicator extraction 을 위해서\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NounScore(frequency=686, score=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_scores['크리스토퍼']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화: NounScore(frequency=61200, score=0.7619601007166377)\n",
      "정말: NounScore(frequency=18842, score=1.0)\n",
      "너무: NounScore(frequency=13708, score=1.0)\n",
      "진짜: NounScore(frequency=14504, score=0.9568345323741008)\n",
      "최고: NounScore(frequency=12792, score=0.8792405063291139)\n",
      "감독: NounScore(frequency=6591, score=1.0)\n",
      "재미: NounScore(frequency=6048, score=0.9528061224489796)\n",
      "생각: NounScore(frequency=5616, score=0.9793271179570329)\n",
      "배우들: NounScore(frequency=5065, score=0.9925449000338868)\n",
      "ㅋㅋ: NounScore(frequency=4880, score=1.0)\n",
      "감동: NounScore(frequency=4902, score=0.9840525328330206)\n",
      "평점: NounScore(frequency=6226, score=0.8520084566596194)\n",
      "마지막: NounScore(frequency=4508, score=1.0)\n",
      "이런: NounScore(frequency=4861, score=0.904540379605508)\n",
      "스토리: NounScore(frequency=4991, score=0.8579169175195666)\n",
      "것: NounScore(frequency=3629, score=1.0)\n",
      "그래: NounScore(frequency=3579, score=0.9900787861103005)\n",
      "느낌: NounScore(frequency=3482, score=1.0)\n",
      "내: NounScore(frequency=3778, score=0.9359138682389131)\n",
      "대박: NounScore(frequency=3174, score=1.0)\n",
      "솔직히: NounScore(frequency=3158, score=1.0)\n",
      "사람: NounScore(frequency=3142, score=0.997948717948718)\n",
      "처음: NounScore(frequency=3532, score=0.9375)\n",
      "놀란: NounScore(frequency=3118, score=0.9966044142614601)\n",
      "사람들: NounScore(frequency=3068, score=0.9974763406940063)\n",
      "심형래: NounScore(frequency=2938, score=1.0)\n",
      "CG: NounScore(frequency=2907, score=0.994368840919756)\n",
      "그리고: NounScore(frequency=2852, score=0.9985994397759104)\n",
      "완전: NounScore(frequency=2760, score=1.0)\n",
      "ㅠㅠ: NounScore(frequency=2759, score=1.0)\n"
     ]
    }
   ],
   "source": [
    "for noun in sorted(noun_scores, key=lambda x:-math.sqrt(noun_scores[x].frequency) * noun_scores[x].score)[:30]:\n",
    "    print('{}: {}'.format(noun, noun_scores[noun]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicator Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicator Extractor] counting eojeols was done. 60208 eojeols, mem=0.333 Gb                    \n",
      "[Predicator Extractor] complete eojeol counter -> lr graph\n",
      "[Predicator Extractor] has been trained. mem=0.333 Gb\n",
      "num stems (before stem extraction) = 1248\n",
      "num eomis (before eomi extraction) = 1120\n",
      "[Eomi Extractor] batch prediction was completed for 5500 words\n",
      "[Eomi Extractor] eomi lemmatization with 714 candidates\n",
      "[Eomi Extractor] 1562 eomis extracted with min frequency = 1, min score = 0.3\n",
      "[Predicator Extractor] 1287 eomis have been extracted\n",
      "[Stem Extractor] Initializing was done with 1248 stems and 2407 eomisis\n",
      "[Stem Extractor] batch prediction for 4695 candidates\n",
      "[Stem Extractor] 37 stems, 18 surfacial stems, 13 removals\n",
      "[Predicator Extractor] 37 stems have been extracted\n",
      "[Predicator Extractor] lemma candidating was done. 64.558 % eojeols are covered\n",
      "[Predicator Extractor] 6474 predicators are extracted\n",
      "num stems (after stem extraction) = 1285\n",
      "num eomis (after eomi extraction) = 2407\n"
     ]
    }
   ],
   "source": [
    "from soynlp.predicator import PredicatorExtractor\n",
    "\n",
    "# prepare materials from noun extractor\n",
    "noun_pos_features = noun_extractor._pos_features\n",
    "nouns = {noun for noun in noun_scores}\n",
    "\n",
    "# initiate\n",
    "predicator_extractor = PredicatorExtractor(\n",
    "    nouns = nouns,\n",
    "    noun_pos_features = noun_pos_features, # \"명사 + 조사/형용사\" 어절을 걸러내기 위함\n",
    "    extract_eomi=True,\n",
    "    extract_stem=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "predicator_extractor.train(\n",
    "    sentences,\n",
    "    min_eojeol_frequency = 3\n",
    ")\n",
    "\n",
    "print('num stems (before stem extraction) = %d' % len(predicator_extractor._stems))\n",
    "print('num eomis (before eomi extraction) = %d' % len(predicator_extractor._eomis))\n",
    "\n",
    "predicators = predicator_extractor.extract(\n",
    "    min_predicator_frequency=3, reset_lrgraph=True,\n",
    "    # Eomi extractor\n",
    "    min_num_of_features=2, min_eomi_score=0.3, min_eomi_frequency=1,\n",
    "    # Stem extractor\n",
    "    min_num_of_unique_R_char=10, min_entropy_of_R_char=0.5,\n",
    "    min_entropy_of_R=1.5, min_stem_score=0.7, min_stem_frequency=5\n",
    ")\n",
    "\n",
    "print('num stems (after stem extraction) = %d' % len(predicator_extractor._stems))\n",
    "print('num eomis (after eomi extraction) = %d' % len(predicator_extractor._eomis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보고: Predicator(frequency=5899, lemma={('보', '고')})\n",
      "내가: Predicator(frequency=3718, lemma={('내', '가'), ('낳', '아가')})\n",
      "봤는데: Predicator(frequency=3560, lemma={('보', '았는데')})\n",
      "하지만: Predicator(frequency=3507, lemma={('하', '지만')})\n",
      "이건: Predicator(frequency=3414, lemma={('이', '건')})\n",
      "있는: Predicator(frequency=2966, lemma={('있', '는'), ('이', 'ㅆ는')})\n",
      "이렇게: Predicator(frequency=2891, lemma={('이렇', '게')})\n",
      "없는: Predicator(frequency=2848, lemma={('없', '는'), ('이', '없는')})\n",
      "보는: Predicator(frequency=2775, lemma={('보', '는')})\n",
      "없다: Predicator(frequency=2686, lemma={('없', '다'), ('이', '없다')})\n",
      "재밌게: Predicator(frequency=2573, lemma={('재밌', '게')})\n",
      "하는: Predicator(frequency=2453, lemma={('하', '는')})\n",
      "좋은: Predicator(frequency=2429, lemma={('좋', '은'), ('좋으', 'ㄴ')})\n",
      "이게: Predicator(frequency=2391, lemma={('이', '게')})\n",
      "내내: Predicator(frequency=2140, lemma={('낳', '아내'), ('내', '내')})\n",
      "보세요: Predicator(frequency=2105, lemma={('보', '세요')})\n",
      "보면: Predicator(frequency=2071, lemma={('보', '면')})\n",
      "같다: Predicator(frequency=1847, lemma={('같', '다')})\n",
      "같은: Predicator(frequency=1703, lemma={('같', '은')})\n",
      "대한: Predicator(frequency=1691, lemma={('대하', 'ㄴ')})\n",
      "만든: Predicator(frequency=1660, lemma={('만드', 'ㄴ')})\n",
      "어떻게: Predicator(frequency=1632, lemma={('어떻', '게')})\n",
      "하고: Predicator(frequency=1554, lemma={('하', '고')})\n",
      "없고: Predicator(frequency=1515, lemma={('이', '없고'), ('없', '고')})\n",
      "많은: Predicator(frequency=1497, lemma={('많', '은')})\n",
      "봤다: Predicator(frequency=1458, lemma={('보', '았다')})\n",
      "봤어요: Predicator(frequency=1392, lemma={('보', '았어요')})\n",
      "다른: Predicator(frequency=1380, lemma={('다르', 'ㄴ')})\n",
      "봐도: Predicator(frequency=1315, lemma={('보', '아도')})\n",
      "만드는: Predicator(frequency=1295, lemma={('만드', '는')})\n",
      "있다: Predicator(frequency=1269, lemma={('있', '다'), ('이', 'ㅆ다')})\n",
      "재밌다: Predicator(frequency=1222, lemma={('재밌', '다')})\n",
      "재밌어요: Predicator(frequency=1178, lemma={('재밌', '어요')})\n",
      "않은: Predicator(frequency=1167, lemma={('않으', 'ㄴ'), ('않', '은')})\n",
      "보면서: Predicator(frequency=1156, lemma={('보', '면서')})\n",
      "끝나고: Predicator(frequency=1090, lemma={('끝나', '고')})\n",
      "좋았다: Predicator(frequency=1084, lemma={('좋', '았다'), ('좋았', '다'), ('좋아', 'ㅆ다'), ('좋으', '았다'), ('좋앟', 'ㅆ다')})\n",
      "않고: Predicator(frequency=1084, lemma={('않', '고')})\n",
      "모르고: Predicator(frequency=1083, lemma={('모르', '고')})\n",
      "싶다: Predicator(frequency=1053, lemma={('싶', '다')})\n",
      "그렇게: Predicator(frequency=1048, lemma={('그렇', '게')})\n",
      "있고: Predicator(frequency=1027, lemma={('이', 'ㅆ고'), ('있', '고')})\n",
      "나도: Predicator(frequency=1027, lemma={('나', '도'), ('낳', '도')})\n",
      "다들: Predicator(frequency=1003, lemma={('닿', '들')})\n",
      "아니라: Predicator(frequency=996, lemma={('아니', '라')})\n",
      "싶은: Predicator(frequency=947, lemma={('싶', '은')})\n",
      "보다: Predicator(frequency=947, lemma={('보', '다')})\n",
      "같아요: Predicator(frequency=927, lemma={('같', '아요')})\n",
      "없이: Predicator(frequency=889, lemma={('없', '이')})\n",
      "있지만: Predicator(frequency=869, lemma={('있', '지만'), ('이', 'ㅆ지만')})\n",
      "------------------------------------------------------------\n",
      "뿌리고: Predicator(frequency=4, lemma={('뿌리', '고')})\n",
      "치워라: Predicator(frequency=4, lemma={('치', '워라'), ('치우', '어라')})\n",
      "걸렸습니다: Predicator(frequency=4, lemma={('걸리', '었습니다')})\n",
      "하라: Predicator(frequency=4, lemma={('하', '라')})\n",
      "안본건: Predicator(frequency=4, lemma={('안보', 'ㄴ건')})\n",
      "안좋았던: Predicator(frequency=4, lemma={('안좋', '았던')})\n",
      "된통: Predicator(frequency=4, lemma={('되', 'ㄴ통')})\n",
      "죽어가는데: Predicator(frequency=4, lemma={('죽', '어가는데'), ('죽이', '어가는데')})\n",
      "죽은거: Predicator(frequency=4, lemma={('죽', '은거')})\n",
      "되겠군: Predicator(frequency=4, lemma={('되', '겠군')})\n",
      "다니지: Predicator(frequency=4, lemma={('다니', '지')})\n",
      "다르죠: Predicator(frequency=4, lemma={('다르', '죠')})\n",
      "어쩌라는: Predicator(frequency=4, lemma={('어쩌', '라는')})\n",
      "대리고: Predicator(frequency=4, lemma={('대', '리고'), ('닿', '아리고')})\n",
      "싸웠음: Predicator(frequency=4, lemma={('싸', '웠음'), ('쓰', '아웠음'), ('쌓', '웠음'), ('싸우', '었음')})\n",
      "자빠진: Predicator(frequency=4, lemma={('자', '빠진')})\n",
      "안좋은건: Predicator(frequency=4, lemma={('안좋', '은건')})\n",
      "힘들었을텐데: Predicator(frequency=4, lemma={('힘들', '었을텐데')})\n",
      "올렸으면: Predicator(frequency=4, lemma={('올리', '었으면')})\n",
      "무서웟음: Predicator(frequency=4, lemma={('무섭', '엇음')})\n",
      "얻었음: Predicator(frequency=4, lemma={('얻', '었음'), ('이', '얻었음')})\n",
      "잘하십니다: Predicator(frequency=4, lemma={('잘하', '십니다')})\n",
      "불러서: Predicator(frequency=4, lemma={('불리', '어서'), ('불', '러서'), ('부르', '어서')})\n",
      "안했다면: Predicator(frequency=4, lemma={('안하', '았다면')})\n",
      "잼없었어요: Predicator(frequency=4, lemma={('잼이', '없었어요')})\n",
      "없지만요: Predicator(frequency=4, lemma={('없', '지만요'), ('이', '없지만요')})\n",
      "홀린다: Predicator(frequency=4, lemma={('홀리', 'ㄴ다')})\n",
      "차는: Predicator(frequency=4, lemma={('차', '는')})\n",
      "보다시피: Predicator(frequency=4, lemma={('보', '다시피')})\n",
      "만들다만: Predicator(frequency=4, lemma={('만들', '다만')})\n",
      "드러워서: Predicator(frequency=4, lemma={('드리', '어워서')})\n",
      "무서워도: Predicator(frequency=4, lemma={('무섭', '어도')})\n",
      "믿거나: Predicator(frequency=4, lemma={('믿', '거나')})\n",
      "걸렸는데: Predicator(frequency=4, lemma={('걸리', '었는데')})\n",
      "막으려는: Predicator(frequency=4, lemma={('막', '으려는')})\n",
      "싸도: Predicator(frequency=4, lemma={('싸', '도'), ('쓰', '아도'), ('쌓', '도')})\n",
      "잘하지: Predicator(frequency=4, lemma={('잘하', '지')})\n",
      "꿰는: Predicator(frequency=4, lemma={('꿰', '는')})\n",
      "넣어놓고: Predicator(frequency=4, lemma={('넣', '어놓고')})\n",
      "무섭단: Predicator(frequency=4, lemma={('무섭', '단')})\n",
      "즐기게: Predicator(frequency=4, lemma={('즐기', '게')})\n",
      "찾아보며: Predicator(frequency=4, lemma={('찾아보', '며')})\n",
      "갑중에: Predicator(frequency=4, lemma={('가', 'ㅂ중에')})\n",
      "해놓은: Predicator(frequency=4, lemma={('하', '아놓은')})\n",
      "읽으니: Predicator(frequency=4, lemma={('읽', '으니')})\n",
      "무서워여: Predicator(frequency=4, lemma={('무섭', '어여')})\n",
      "물릴: Predicator(frequency=4, lemma={('물', '릴'), ('물리', 'ㄹ')})\n",
      "좋아할지: Predicator(frequency=4, lemma={('좋아하', 'ㄹ지')})\n",
      "켜고: Predicator(frequency=4, lemma={('켜', '고')})\n",
      "일어나느냐: Predicator(frequency=4, lemma={('일어나', '느냐')})\n",
      "꿰뚫는: Predicator(frequency=4, lemma={('꿰뚫', '는')})\n",
      "맞추니: Predicator(frequency=4, lemma={('맞추', '니')})\n",
      "만났으면: Predicator(frequency=4, lemma={('만나', 'ㅆ으면')})\n",
      "되야한다: Predicator(frequency=4, lemma={('되', '야한다')})\n",
      "하기위해: Predicator(frequency=4, lemma={('하', '기위해')})\n",
      "색달라서: Predicator(frequency=4, lemma={('색다르', '아서')})\n",
      "아니든: Predicator(frequency=4, lemma={('아니', '든')})\n",
      "견디기: Predicator(frequency=4, lemma={('견디', '기')})\n",
      "재밌으니: Predicator(frequency=4, lemma={('재밌', '으니')})\n",
      "감을: Predicator(frequency=4, lemma={('감', '을')})\n",
      "먹던: Predicator(frequency=4, lemma={('먹', '던')})\n",
      "할꺼면: Predicator(frequency=4, lemma={('하', 'ㄹ꺼면')})\n",
      "다룬다: Predicator(frequency=4, lemma={('다루', 'ㄴ다')})\n",
      "잇을까: Predicator(frequency=4, lemma={('잇', '을까')})\n",
      "업음: Predicator(frequency=4, lemma={('이', '업음'), ('업', '음')})\n",
      "치자면: Predicator(frequency=4, lemma={('치', '자면')})\n",
      "꼬다가: Predicator(frequency=4, lemma={('꼬', '다가')})\n",
      "더러워요: Predicator(frequency=4, lemma={('더럽', '어요')})\n",
      "있게하는: Predicator(frequency=4, lemma={('이', 'ㅆ게하는'), ('있', '게하는')})\n",
      "돋보이네요: Predicator(frequency=4, lemma={('돋보이', '네요')})\n",
      "불러온: Predicator(frequency=4, lemma={('불', '러온'), ('부르', '어온'), ('불리', '어온')})\n",
      "되야할: Predicator(frequency=4, lemma={('되', '야할')})\n",
      "망쳤네: Predicator(frequency=4, lemma={('망치', '었네')})\n",
      "못한거다: Predicator(frequency=4, lemma={('못하', 'ㄴ거다')})\n",
      "오니까: Predicator(frequency=4, lemma={('오', '니까')})\n",
      "치우쳐서: Predicator(frequency=4, lemma={('치우치', '어서')})\n",
      "많더라구요: Predicator(frequency=4, lemma={('많', '더라구요')})\n",
      "안했어: Predicator(frequency=4, lemma={('안하', '았어')})\n",
      "물린: Predicator(frequency=4, lemma={('물리', 'ㄴ'), ('물', '린')})\n",
      "뭉친: Predicator(frequency=4, lemma={('뭉치', 'ㄴ')})\n",
      "찾아보는데: Predicator(frequency=4, lemma={('찾아보', '는데')})\n",
      "만들며: Predicator(frequency=4, lemma={('만들', '며'), ('만드', 'ㄹ며')})\n",
      "끝내면: Predicator(frequency=4, lemma={('끝내', '면')})\n",
      "먹히는: Predicator(frequency=4, lemma={('먹히', '는')})\n",
      "드물게: Predicator(frequency=4, lemma={('드물', '게')})\n",
      "당당하게: Predicator(frequency=4, lemma={('당당하', '게')})\n",
      "깨기: Predicator(frequency=4, lemma={('깨', '기')})\n",
      "튀어나오고: Predicator(frequency=4, lemma={('튀', '어나오고'), ('튀어나오', '고')})\n",
      "갈리고: Predicator(frequency=4, lemma={('갈', '리고'), ('가', 'ㄹ리고')})\n",
      "놀랐지만: Predicator(frequency=4, lemma={('놀', '랐지만'), ('놀라', 'ㅆ지만')})\n",
      "더하는: Predicator(frequency=4, lemma={('더하', '는')})\n",
      "아니라구: Predicator(frequency=4, lemma={('아니', '라구')})\n",
      "말듯: Predicator(frequency=4, lemma={('말', '듯')})\n",
      "잘나온: Predicator(frequency=4, lemma={('잘나', '온')})\n",
      "계시다면: Predicator(frequency=4, lemma={('계시', '다면')})\n",
      "풀려고: Predicator(frequency=4, lemma={('푸', 'ㄹ려고'), ('풀', '려고'), ('풀리', '어고')})\n",
      "늘어놓고: Predicator(frequency=4, lemma={('늘어놓', '고'), ('늘', '어놓고')})\n",
      "들림: Predicator(frequency=4, lemma={('들', '림')})\n",
      "들어가게: Predicator(frequency=4, lemma={('들이', '어가게'), ('들어가', '게'), ('들', '어가게'), ('듣', '어가게')})\n",
      "좋았으며: Predicator(frequency=4, lemma={('좋', '았으며'), ('좋아', 'ㅆ으며'), ('좋앟', 'ㅆ으며'), ('좋으', '았으며'), ('좋았', '으며')})\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "frequency_sorted_predicators = sorted(predicators, key=lambda x: -predicators[x].frequency)\n",
    "\n",
    "word_sets = [\n",
    "    frequency_sorted_predicators[:50],\n",
    "    frequency_sorted_predicators[-500:-400]\n",
    "]\n",
    "\n",
    "for word_set in word_sets:\n",
    "    for word in word_set:\n",
    "        lemmas = predicators[word]\n",
    "        print('{}: {}'.format(word, lemmas))\n",
    "    print('--' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=1260, neg=1173, common=12\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from soynlp.utils import LRGraph\n",
    "\n",
    "# build noun extractor from {l:{r:count}} dict\n",
    "with open('../tmp/lrgraph_dict_for_nounextraction.pkl', 'rb') as f:\n",
    "    lrgraph = LRGraph(pickle.load(f))\n",
    "\n",
    "chat_noun_extractor = LRNounExtractor_v2(\n",
    "    extract_pos_feature=True\n",
    ")\n",
    "\n",
    "chat_noun_extractor.lrgraph = lrgraph\n",
    "chat_noun_extractor._num_of_eojeols = lrgraph.to_EojeolCounter()._count_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] extract and append pos features\n",
      "[Noun Extractor] batch prediction for extracting pos feature\n",
      "[Noun Extractor] batch prediction was completed for 167504 words\n",
      "[Noun Extractor] features appended. pos=1260 -> 1260, neg=1173 -> 1173, common=12 -> 12\n",
      "[Noun Extractor] 0 pos features were extracted\n",
      "[Noun Extractor] batch prediction was completed for 167504 words\n",
      "[Noun Extractor] checked compounds. discovered 13 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 58046 -> 56981\n",
      "[Noun Extractor] postprocessing ignore_features : 56981 -> 56867\n",
      "[Noun Extractor] postprocessing ignore_NJ : 56867 -> 55706\n",
      "[Noun Extractor] 55706 nouns (13 compounds) with min frequency=2\n",
      "[Noun Extractor] flushing was done. mem=1.783 Gb                    \n",
      "[Noun Extractor] 58.14 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "chat_noun_scores = chat_noun_extractor.extract(\n",
    "    min_noun_score=0.3,\n",
    "    min_noun_frequency=2,  # 추출되는 명사의 최소 빈도수\n",
    "    reset_lrgraph=False    # predicator extraction 을 위해서\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여부: NounScore(frequency=4831, score=0.7579092159559835)\n",
      "서가앤쿡: NounScore(frequency=121, score=1.0)\n",
      "맘스터치: NounScore(frequency=336, score=0.9178082191780822)\n",
      "신라스테이: NounScore(frequency=11, score=1.0)\n",
      "설입: NounScore(frequency=71, score=1.0)\n"
     ]
    }
   ],
   "source": [
    "for word in '여부 서가앤쿡 맘스터치 신라스테이 설입 '.split():\n",
    "    print('{}: {}'.format(word, chat_noun_scores.get(word, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내: NounScore(frequency=253502, score=0.9581029653240607)\n",
      "그래: NounScore(frequency=219531, score=0.8884650675055709)\n",
      "오늘: NounScore(frequency=202989, score=0.9519450800915332)\n",
      "진짜: NounScore(frequency=184587, score=0.8989955357142857)\n",
      "근데: NounScore(frequency=173788, score=0.8535127055306427)\n",
      "너무: NounScore(frequency=157721, score=0.9843899330997132)\n",
      "그냥: NounScore(frequency=147720, score=0.7358490566037735)\n",
      "오빠: NounScore(frequency=146246, score=0.9886392234405896)\n",
      "지금: NounScore(frequency=140182, score=0.8701720220707563)\n",
      "그럼: NounScore(frequency=132727, score=0.8043704474505723)\n",
      "사랑: NounScore(frequency=121283, score=0.9992462852630823)\n",
      "내일: NounScore(frequency=101316, score=0.7156619678401926)\n",
      "많이: NounScore(frequency=100460, score=0.8667058132706987)\n",
      "응응: NounScore(frequency=85628, score=1.0)\n",
      "우리: NounScore(frequency=84382, score=0.9788417943257539)\n",
      "너: NounScore(frequency=78604, score=0.9711176803572552)\n",
      "미안: NounScore(frequency=73317, score=0.9991863447421951)\n",
      "헤헤: NounScore(frequency=71407, score=1.0)\n",
      "안: NounScore(frequency=66868, score=0.38802360452742574)\n",
      "아직: NounScore(frequency=65260, score=0.9390134529147982)\n",
      "여보: NounScore(frequency=59828, score=0.8183999494853823)\n",
      "집: NounScore(frequency=59661, score=0.9332257044421883)\n",
      "아니야: NounScore(frequency=56098, score=0.9747235387045814)\n",
      "N시: NounScore(frequency=52528, score=0.62901682705836)\n",
      "그거: NounScore(frequency=52374, score=0.7145943610240899)\n",
      "어제: NounScore(frequency=50444, score=0.9713145422798702)\n",
      "생각: NounScore(frequency=49885, score=0.9846913128912854)\n",
      "아냐: NounScore(frequency=44511, score=0.5486725663716814)\n",
      "계속: NounScore(frequency=42252, score=0.8161490683229814)\n",
      "이거: NounScore(frequency=42248, score=0.4708261120739457)\n",
      "엄청: NounScore(frequency=41633, score=0.8320610687022901)\n",
      "바: NounScore(frequency=40726, score=0.8274321072533517)\n",
      "정말: NounScore(frequency=38508, score=0.994475138121547)\n",
      "엄마: NounScore(frequency=37122, score=0.9857083100948132)\n",
      "사람: NounScore(frequency=36428, score=0.9862014587029371)\n",
      "일단: NounScore(frequency=36192, score=0.7647058823529411)\n",
      "몰라: NounScore(frequency=33995, score=0.6929069956175945)\n",
      "자기야: NounScore(frequency=33362, score=0.9865771812080537)\n",
      "N분: NounScore(frequency=33043, score=0.9884685151593677)\n",
      "완전: NounScore(frequency=33030, score=1.0)\n",
      "그런: NounScore(frequency=32171, score=0.5721669466339321)\n",
      "아까: NounScore(frequency=31241, score=0.4425740464521628)\n",
      "이따: NounScore(frequency=30570, score=0.66867705804026)\n",
      "먹고: NounScore(frequency=28337, score=0.6160970935803258)\n",
      "말: NounScore(frequency=27735, score=0.548855608929076)\n",
      "언제: NounScore(frequency=27686, score=0.589914505144182)\n",
      "뭐: NounScore(frequency=27612, score=0.32054821534214156)\n",
      "뭐야: NounScore(frequency=27138, score=0.9054054054054054)\n",
      "무슨: NounScore(frequency=26892, score=1.0)\n",
      "나랑: NounScore(frequency=26433, score=0.6682464454976303)\n",
      "------------------------------------------------------------\n",
      "설정: NounScore(frequency=512, score=1.0)\n",
      "드립: NounScore(frequency=512, score=1.0)\n",
      "팩: NounScore(frequency=512, score=1.0)\n",
      "들어갈때: NounScore(frequency=511, score=1.0)\n",
      "볼꺼야: NounScore(frequency=511, score=1.0)\n",
      "친절: NounScore(frequency=511, score=1.0)\n",
      "고터: NounScore(frequency=511, score=0.9545454545454546)\n",
      "소파: NounScore(frequency=511, score=1.0)\n",
      "키야: NounScore(frequency=511, score=1.0)\n",
      "됴: NounScore(frequency=511, score=0.562874251497006)\n",
      "경기도: NounScore(frequency=510, score=1.0)\n",
      "합격: NounScore(frequency=510, score=0.8901960784313725)\n",
      "파티: NounScore(frequency=510, score=0.8248847926267281)\n",
      "봄봄: NounScore(frequency=510, score=1.0)\n",
      "중학교때: NounScore(frequency=509, score=1.0)\n",
      "없으니깐: NounScore(frequency=509, score=1.0)\n",
      "서영이: NounScore(frequency=509, score=1.0)\n",
      "버거킹: NounScore(frequency=509, score=1.0)\n",
      "잘햇네: NounScore(frequency=509, score=0.30434782608695654)\n",
      "밥맛: NounScore(frequency=509, score=1.0)\n",
      "밴드: NounScore(frequency=509, score=0.7040816326530612)\n",
      "한창: NounScore(frequency=509, score=1.0)\n",
      "해쪄: NounScore(frequency=509, score=0.9016393442622951)\n",
      "주인공: NounScore(frequency=508, score=1.0)\n",
      "차로: NounScore(frequency=508, score=1.0)\n",
      "깼다: NounScore(frequency=508, score=0.7014925373134329)\n",
      "N야: NounScore(frequency=508, score=1.0)\n",
      "지영이: NounScore(frequency=507, score=1.0)\n",
      "안나네: NounScore(frequency=507, score=0.9168173598553345)\n",
      "완성: NounScore(frequency=507, score=0.9815668202764977)\n",
      "재수: NounScore(frequency=507, score=1.0)\n",
      "가긴: NounScore(frequency=507, score=1.0)\n",
      "모의고사: NounScore(frequency=506, score=0.9368421052631579)\n",
      "비밀번호: NounScore(frequency=506, score=1.0)\n",
      "목도리: NounScore(frequency=506, score=1.0)\n",
      "에라이: NounScore(frequency=506, score=1.0)\n",
      "쉴때: NounScore(frequency=506, score=1.0)\n",
      "N천: NounScore(frequency=506, score=0.75)\n",
      "얘기하구: NounScore(frequency=505, score=1.0)\n",
      "그생각: NounScore(frequency=505, score=1.0)\n",
      "이성: NounScore(frequency=505, score=0.9840848806366048)\n",
      "세명: NounScore(frequency=505, score=0.9797979797979798)\n",
      "인누: NounScore(frequency=505, score=0.9)\n",
      "저녁때: NounScore(frequency=504, score=0.8837209302325582)\n",
      "아야: NounScore(frequency=504, score=0.5206611570247934)\n",
      "해놔: NounScore(frequency=504, score=0.31004366812227074)\n",
      "집인데: NounScore(frequency=503, score=0.7872340425531915)\n",
      "진도: NounScore(frequency=503, score=1.0)\n",
      "확률: NounScore(frequency=503, score=1.0)\n",
      "욕을: NounScore(frequency=503, score=1.0)\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "word_sets = [\n",
    "    sorted(chat_noun_scores, key=lambda x:-chat_noun_scores[x].frequency)[:50],\n",
    "    sorted(chat_noun_scores, key=lambda x:-chat_noun_scores[x].frequency)[3000:3050]\n",
    "]\n",
    "for word_set in word_sets:\n",
    "    for noun in word_set:\n",
    "        print('{}: {}'.format(noun, chat_noun_scores[noun]))\n",
    "    print('--' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "1. N is N+J postprocessing 에서 길이가 2 이하인 단어를 pass 하다보니 \"욕 + 을\" 이 명사로 추출. 두 글자의 명사는 각 글자가 명사, 조사인 경우가 많아서 이는 postprocessing 으로 처리하기 어려움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicator Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num stems (before stem extraction) = 1248\n",
      "num eomis (before eomi extraction) = 1120\n",
      "[Eomi Extractor] batch prediction was completed for 103217 words\n",
      "[Eomi Extractor] eomi lemmatization with 5460 candidates\n",
      "[Eomi Extractor] 11511 eomis extracted with min frequency = 10, min score = 0.3\n",
      "[Predicator Extractor] 10994 eomis have been extracted\n",
      "[Stem Extractor] Initializing was done with 1248 stems and 12114 eomisis\n",
      "[Stem Extractor] batch prediction for 58689 candidates\n",
      "[Stem Extractor] 2558 stems, 1584 surfacial stems, 2888 removals\n",
      "[Predicator Extractor] 2528 stems have been extracted\n",
      "[Predicator Extractor] lemma candidating was done. 70.088 % eojeols are covered\n",
      "[Predicator Extractor] 75327 predicators are extracted\n",
      "num stems (after stem extraction) = 3776\n",
      "num eomis (after eomi extraction) = 12114\n"
     ]
    }
   ],
   "source": [
    "from soynlp.predicator import PredicatorExtractor\n",
    "\n",
    "# prepare materials from noun extractor\n",
    "chat_noun_pos_features = chat_noun_extractor._pos_features\n",
    "chat_nouns = {noun for noun in chat_noun_scores}\n",
    "chat_lrgraph = LRGraph(chat_noun_extractor.lrgraph._lr)\n",
    "\n",
    "# initiate\n",
    "chat_predicator_extractor = PredicatorExtractor(\n",
    "    nouns = chat_nouns,\n",
    "    noun_pos_features = chat_noun_pos_features, # \"명사 + 조사/형용사\" 어절을 걸러내기 위함\n",
    "    extract_eomi=True,\n",
    "    extract_stem=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chat_predicator_extractor.train(\n",
    "    #sentences,\n",
    "    chat_lrgraph, # sentence 대신 LRGraph 를 넣어도 됨\n",
    "    min_eojeol_frequency = 3\n",
    ")\n",
    "\n",
    "print('num stems (before stem extraction) = %d' % len(chat_predicator_extractor._stems))\n",
    "print('num eomis (before eomi extraction) = %d' % len(chat_predicator_extractor._eomis))\n",
    "\n",
    "chat_predicators = chat_predicator_extractor.extract(\n",
    "    min_predicator_frequency=5, reset_lrgraph=True,\n",
    "    # Eomi extractor\n",
    "    min_num_of_features=4, min_eomi_score=0.3, min_eomi_frequency=10,\n",
    "    # Stem extractor\n",
    "    min_num_of_unique_R_char=5, min_entropy_of_R_char=0.5,\n",
    "    min_entropy_of_R=1.5, min_stem_score=0.7, min_stem_frequency=5\n",
    ")\n",
    "\n",
    "print('num stems (after stem extraction) = %d' % len(chat_predicator_extractor._stems))\n",
    "print('num eomis (after eomi extraction) = %d' % len(chat_predicator_extractor._eomis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가: Predicator(frequency=251537, lemma={('내', '가'), ('내그', '아'), ('낳', '아가')})\n",
      "이제: Predicator(frequency=170348, lemma={('이', '제')})\n",
      "나도: Predicator(frequency=150243, lemma={('나', '도'), ('낳', '도')})\n",
      "나는: Predicator(frequency=96965, lemma={('나', '는'), ('낳', '는')})\n",
      "자기: Predicator(frequency=88198, lemma={('자', '기')})\n",
      "같이: Predicator(frequency=61417, lemma={('같', '이')})\n",
      "다시: Predicator(frequency=43174, lemma={('닿', '시')})\n",
      "그렇게: Predicator(frequency=41940, lemma={('그렇', '게')})\n",
      "하고: Predicator(frequency=40197, lemma={('하', '고')})\n",
      "나두: Predicator(frequency=40086, lemma={('낳', '두'), ('나', '두')})\n",
      "너가: Predicator(frequency=38115, lemma={('너그', '아'), ('넣', '가')})\n",
      "그리고: Predicator(frequency=34275, lemma={('그리', '고')})\n",
      "빨리: Predicator(frequency=33545, lemma={('빨', '리')})\n",
      "좋아: Predicator(frequency=30761, lemma={('좋', '아')})\n",
      "어떻게: Predicator(frequency=29312, lemma={('어떻', '게')})\n",
      "있어: Predicator(frequency=29049, lemma={('이', 'ㅆ어'), ('있', '어')})\n",
      "이렇게: Predicator(frequency=26173, lemma={('이렇', '게')})\n",
      "맞아: Predicator(frequency=25697, lemma={('맞', '아')})\n",
      "보고: Predicator(frequency=25504, lemma={('보', '고')})\n",
      "갑자기: Predicator(frequency=24793, lemma={('가', 'ㅂ자기')})\n",
      "자기가: Predicator(frequency=24372, lemma={('자', '기가')})\n",
      "그러면: Predicator(frequency=23537, lemma={('그렇', '면'), ('그르', '어면'), ('그러', '면'), ('그리', '어면')})\n",
      "없어: Predicator(frequency=23525, lemma={('없', '어'), ('이', '없어')})\n",
      "일찍: Predicator(frequency=22957, lemma={('일', '찍'), ('이', 'ㄹ찍')})\n",
      "하면: Predicator(frequency=22670, lemma={('하', '면')})\n",
      "잘자: Predicator(frequency=21665, lemma={('잘', '자'), ('자', 'ㄹ자'), ('잘즈', '아')})\n",
      "안돼: Predicator(frequency=21330, lemma={('안', '돼')})\n",
      "고마워: Predicator(frequency=20756, lemma={('고맙', '어')})\n",
      "괜찮아: Predicator(frequency=20253, lemma={('괜찮', '아')})\n",
      "오오: Predicator(frequency=18240, lemma={('오', '오')})\n",
      "해서: Predicator(frequency=17518, lemma={('하', '아서')})\n",
      "하나: Predicator(frequency=16701, lemma={('하', '나')})\n",
      "아니면: Predicator(frequency=16685, lemma={('아니', '면')})\n",
      "귀여워: Predicator(frequency=16531, lemma={('귀엽', '어')})\n",
      "이미: Predicator(frequency=16479, lemma={('이', '미')})\n",
      "알겠어: Predicator(frequency=15195, lemma={('알', '겠어'), ('알겋', '었어')})\n",
      "이게: Predicator(frequency=15063, lemma={('이', '게')})\n",
      "씻고: Predicator(frequency=15057, lemma={('씻', '고')})\n",
      "여기: Predicator(frequency=15053, lemma={('이', '어기')})\n",
      "너도: Predicator(frequency=14958, lemma={('넣', '도')})\n",
      "누가: Predicator(frequency=14798, lemma={('누', '가')})\n",
      "했는데: Predicator(frequency=14530, lemma={('하', '았는데')})\n",
      "같아: Predicator(frequency=14168, lemma={('같', '아')})\n",
      "자기는: Predicator(frequency=13446, lemma={('자', '기는')})\n",
      "아니고: Predicator(frequency=13349, lemma={('아니', '고')})\n",
      "먹어: Predicator(frequency=13159, lemma={('먹', '어'), ('먹이', '어')})\n",
      "이런: Predicator(frequency=12979, lemma={('이렇', 'ㄴ'), ('이러', 'ㄴ')})\n",
      "이건: Predicator(frequency=12633, lemma={('이', '건')})\n",
      "있는데: Predicator(frequency=12308, lemma={('있', '는데'), ('이', 'ㅆ는데')})\n",
      "늦게: Predicator(frequency=12301, lemma={('늦', '게')})\n",
      "------------------------------------------------------------\n",
      "반해서: Predicator(frequency=74, lemma={('반하', '아서')})\n",
      "않으니깐: Predicator(frequency=74, lemma={('않', '으니깐')})\n",
      "느끼기엔: Predicator(frequency=74, lemma={('느끼', '기엔')})\n",
      "사먹으면: Predicator(frequency=74, lemma={('사먹', '으면'), ('사미', '억으면'), ('사므', '억으면')})\n",
      "앉는: Predicator(frequency=74, lemma={('앉', '는')})\n",
      "잘되는: Predicator(frequency=74, lemma={('잘되', '는')})\n",
      "안닮았어: Predicator(frequency=74, lemma={('안닮', '았어')})\n",
      "톡보내고: Predicator(frequency=74, lemma={('톡보낳', '아고'), ('톡보내', '고')})\n",
      "있단다: Predicator(frequency=74, lemma={('이', 'ㅆ단다'), ('있', '단다'), ('있닿', 'ㄴ다')})\n",
      "친하면: Predicator(frequency=74, lemma={('친하', '면')})\n",
      "끄면: Predicator(frequency=74, lemma={('끄', '면')})\n",
      "서고: Predicator(frequency=74, lemma={('서', '고')})\n",
      "안아주면서: Predicator(frequency=74, lemma={('안', '아주면서'), ('안으', '아주면서')})\n",
      "덥넹: Predicator(frequency=74, lemma={('덥', '넹')})\n",
      "고마워욤: Predicator(frequency=74, lemma={('고맙', '어욤')})\n",
      "매고: Predicator(frequency=74, lemma={('매', '고')})\n",
      "잘해보자: Predicator(frequency=74, lemma={('잘하', '아보자')})\n",
      "가지만: Predicator(frequency=74, lemma={('가', '지만')})\n",
      "나아용: Predicator(frequency=74, lemma={('낳', '아용'), ('나', '아용'), ('낫', '아용'), ('나으', '아용')})\n",
      "이봐요: Predicator(frequency=74, lemma={('이', '봐요')})\n",
      "하라며: Predicator(frequency=74, lemma={('하', '라며')})\n",
      "해봐도: Predicator(frequency=74, lemma={('해보', '아도')})\n",
      "사기로: Predicator(frequency=74, lemma={('사', '기로')})\n",
      "잘잣니: Predicator(frequency=74, lemma={('잘즈', '앗니')})\n",
      "댄다: Predicator(frequency=74, lemma={('닿', '안다'), ('대', 'ㄴ다')})\n",
      "집이죠: Predicator(frequency=74, lemma={('집이', '죠')})\n",
      "믿을께: Predicator(frequency=74, lemma={('믿', '을께')})\n",
      "물어봐야: Predicator(frequency=74, lemma={('물어보', '아야'), ('묻', '어봐야'), ('물', '어봐야')})\n",
      "놀라게: Predicator(frequency=74, lemma={('놀라', '게'), ('놀랗', '게')})\n",
      "왔냐: Predicator(frequency=74, lemma={('오', '았냐')})\n",
      "왔냐고: Predicator(frequency=74, lemma={('오', '았냐고')})\n",
      "맛있넹: Predicator(frequency=74, lemma={('맛있', '넹'), ('맛이', 'ㅆ넹')})\n",
      "그러시군요: Predicator(frequency=74, lemma={('그르', '어시군요'), ('그러', '시군요'), ('그렇', '시군요'), ('그리', '어시군요')})\n",
      "가야한다고: Predicator(frequency=74, lemma={('가', '야한다고')})\n",
      "말해야겠다: Predicator(frequency=74, lemma={('말해', '야겠다'), ('말햇', '야겠다'), ('말하', '아야겠다'), ('말핳', '아야겠다')})\n",
      "몰고: Predicator(frequency=74, lemma={('몰', '고')})\n",
      "배곺: Predicator(frequency=74, lemma={('배', '곺')})\n",
      "느꼈던: Predicator(frequency=73, lemma={('느끼', '었던')})\n",
      "꾸는: Predicator(frequency=73, lemma={('꾸', '는')})\n",
      "안자넹: Predicator(frequency=73, lemma={('안', '자넹'), ('안자', '넹'), ('안잫', '넹'), ('안즈', '아넹')})\n",
      "먹엇징: Predicator(frequency=73, lemma={('먹이', '엇징'), ('먹', '엇징')})\n",
      "하구있어요: Predicator(frequency=73, lemma={('하', '구있어요')})\n",
      "그러네용: Predicator(frequency=73, lemma={('그르', '어네용'), ('그렇', '네용'), ('그러', '네용'), ('그리', '어네용')})\n",
      "해야쥐: Predicator(frequency=73, lemma={('하', '아야쥐')})\n",
      "안먹어봄: Predicator(frequency=73, lemma={('안먹', '어봄')})\n",
      "그랬으면서: Predicator(frequency=73, lemma={('그렇', '았으면서')})\n",
      "믿어서: Predicator(frequency=73, lemma={('믿', '어서')})\n",
      "안받게: Predicator(frequency=73, lemma={('안받', '게')})\n",
      "듣는건: Predicator(frequency=73, lemma={('듣', '는건')})\n",
      "붓기: Predicator(frequency=73, lemma={('붓', '기')})\n",
      "원하고: Predicator(frequency=73, lemma={('원하', '고')})\n",
      "흘려: Predicator(frequency=73, lemma={('흘리', '어')})\n",
      "술안먹고: Predicator(frequency=73, lemma={('술안므', '억고'), ('술안미', '억고'), ('술안먹', '고')})\n",
      "너같이: Predicator(frequency=73, lemma={('너같', '이')})\n",
      "바보같다: Predicator(frequency=73, lemma={('바보같', '다')})\n",
      "모햅: Predicator(frequency=73, lemma={('모하', '압'), ('모핳', '압')})\n",
      "잘모르겠다: Predicator(frequency=73, lemma={('잘모르', '겠다')})\n",
      "띵해: Predicator(frequency=73, lemma={('띵하', '아'), ('띵핳', '아')})\n",
      "누워땅: Predicator(frequency=73, lemma={('눕', '어땅')})\n",
      "다하지: Predicator(frequency=73, lemma={('다하', '지')})\n",
      "찌고: Predicator(frequency=73, lemma={('찌', '고')})\n",
      "봤고: Predicator(frequency=73, lemma={('보', '았고')})\n",
      "없는가: Predicator(frequency=73, lemma={('이', '없는가'), ('없', '는가')})\n",
      "챙겨갈게: Predicator(frequency=73, lemma={('챙겨그', '알게'), ('챙겨갛', 'ㄹ게'), ('챙겨가', 'ㄹ게')})\n",
      "올리는거: Predicator(frequency=73, lemma={('올리', '는거')})\n",
      "그러지말라고: Predicator(frequency=73, lemma={('그러', '지말라고'), ('그르', '어지말라고'), ('그리', '어지말라고'), ('그렇', '지말라고')})\n",
      "잘자랏: Predicator(frequency=73, lemma={('잘즈', '아랏'), ('잘자', '랏'), ('잘잫', '랏')})\n",
      "피지: Predicator(frequency=73, lemma={('피', '지')})\n",
      "되겠구나: Predicator(frequency=73, lemma={('되', '겠구나')})\n",
      "맘에드는데: Predicator(frequency=73, lemma={('맘에드', '는데')})\n",
      "괜찮아졋어: Predicator(frequency=73, lemma={('괜찮', '아졋어')})\n",
      "줫는데: Predicator(frequency=73, lemma={('주', '엇는데')})\n",
      "되냐구: Predicator(frequency=73, lemma={('되', '냐구')})\n",
      "밖이라: Predicator(frequency=73, lemma={('밖이', '라')})\n",
      "말기: Predicator(frequency=73, lemma={('말', '기')})\n",
      "이렇지: Predicator(frequency=73, lemma={('이렇', '지')})\n",
      "남기면: Predicator(frequency=73, lemma={('남기', '면')})\n",
      "와주면: Predicator(frequency=73, lemma={('오', '아주면')})\n",
      "보구있어: Predicator(frequency=73, lemma={('보', '구있어')})\n",
      "잘게영: Predicator(frequency=73, lemma={('잘', '게영'), ('자', 'ㄹ게영')})\n",
      "너냐: Predicator(frequency=73, lemma={('넣', '냐')})\n",
      "있는거같은데: Predicator(frequency=73, lemma={('이', 'ㅆ는거같은데'), ('있', '는거같은데')})\n",
      "기쁘고: Predicator(frequency=73, lemma={('기쁘', '고')})\n",
      "쉬는거지: Predicator(frequency=73, lemma={('쉬', '는거지')})\n",
      "치는게: Predicator(frequency=73, lemma={('치', '는게')})\n",
      "바쁘죠: Predicator(frequency=73, lemma={('바쁘', '죠')})\n",
      "넘겨서: Predicator(frequency=73, lemma={('넘기', '어서')})\n",
      "안들림: Predicator(frequency=73, lemma={('안드', 'ㄹ림')})\n",
      "보려구요: Predicator(frequency=73, lemma={('보', '려구요')})\n",
      "나같아: Predicator(frequency=73, lemma={('나같', '아')})\n",
      "데려가서: Predicator(frequency=73, lemma={('데리', '어가서'), ('데려가', '서')})\n",
      "괜찮소: Predicator(frequency=73, lemma={('괜찮', '소')})\n",
      "통했네: Predicator(frequency=73, lemma={('통하', '았네')})\n",
      "배웠는데: Predicator(frequency=73, lemma={('배', '웠는데'), ('배우', '었는데')})\n",
      "기다리는동안: Predicator(frequency=73, lemma={('기다리', '는동안')})\n",
      "누구요: Predicator(frequency=73, lemma={('누', '구요')})\n",
      "똑같잖아: Predicator(frequency=73, lemma={('똑같', '잖아')})\n",
      "이쁘군: Predicator(frequency=73, lemma={('이쁘', '군')})\n",
      "늦지말고: Predicator(frequency=73, lemma={('늦', '지말고')})\n",
      "있다해서: Predicator(frequency=73, lemma={('있', '다해서'), ('이', 'ㅆ다해서')})\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "frequency_sorted_chat_predicators = sorted(chat_predicators, key=lambda x: -chat_predicators[x].frequency)\n",
    "\n",
    "word_sets = [\n",
    "    frequency_sorted_chat_predicators[:50],\n",
    "    frequency_sorted_chat_predicators[10400:10500]\n",
    "]\n",
    "\n",
    "for word_set in word_sets:\n",
    "    for word in word_set:\n",
    "        lemmas = chat_predicators[word]\n",
    "        print('{}: {}'.format(word, lemmas))\n",
    "    print('--' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
